[
  {
    "objectID": "posts/vision/04-neural-networks-in-pytorch.html",
    "href": "posts/vision/04-neural-networks-in-pytorch.html",
    "title": "Neural Networks in PyTorch | Log #004",
    "section": "",
    "text": "Until now, we have understood what an image is and the operations that are done to better extract information from them. Now it’s time to dive deep into Neural Networks. This blog will introduce a lot of new concepts and I hope to write separate blogs explaining some of those concepts in depth.\nPyTorch is one of the most popular deep learning frameworks and provides some of the core functionalities required for building a neural network. I find this highly intuitive and there’s always scope to dig deep if want to better understand something by writing from scratch.\n\n\nPyTorch has domain specific libraries like torchtext, torchvision, torchaudio which provide very useful building blocks along with some of the popular datasets.\nFor this example, we will do a simple image classification task with FashionMNIST dataset. The dataset consists of 28x28 grayscale images, each associated with a single label from 10 classes. There are 60k training examples and 10k testing examples.\n\nimport torch\nfrom torch import nn\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data import DataLoader\n\ntraining_data = datasets.FashionMNIST(root=\"data\", download=True, train=True, transform=ToTensor())\ntest_data = datasets.FashionMNIST(root=\"data\", download=True, train=False, transform=ToTensor())\n\nThe above code downloads the data into the root folder and applys the transformations. This provides a Dataset object that stores the sample and their corresponding labels. We want to batch our data to feed them into the model iteratively, using the DataLoader class. This wraps an iterable over the dataset and supports multiprocess data loading and automatic batching.\n\nbatch_size = 64\n\ntrain_dataloader = DataLoader(dataset=training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=batch_size)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"------------- Using {device} ------------\")\n\nWe have created a batch of 64 elements in the dataloader which will return 64 features and labels per batch.\n\n\n\nNow let’s create a simple neural network. Every module in PyTorch inherits from nn.Module. We will define our model in the __init__ function and the forward pass in forward funtion which get’s called automatically.\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n\nNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\n\nNow that we have a model, let’s define a loss function and an optimizer which will help us train the model.\nLoss function simply measures the difference between the predicted output value and the actual target value. This loss is what we need to minimize during training.\nOptimizer is defined as the process of reducing the model error step by step during training. And there are many ways to implement this. This is how our model is learning to perform better. In a training loop, we call the optimizer to replace the gradients of model paramenters using backpropagation. We will look into these algorithms in depth separately.\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    if batch % 100==0:\n        loss, current = loss.item(), (batch + 1) * len(x)\n        print(f\"Training: \\n loss: {loss:&gt;7f} [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss = loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")\n\nWe pass the train and test data through the model and calculate the losses and accuracy. Each full pass through the data is called an Epoch.\n\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\nNow that we have a model, we can save it and load for deployment. We can also do inference to see how the model performs for new data.\n\ntorch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch model state to model.pth\")\n\n\nmodel = NeuralNetwork().to(device)\nmodel.load_state_dict(torch.load(\"model.pth\"), weights_only=True)\n\n\nclasses = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    x = x.to(device)\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n\nThere is a lot of concepts we introduced in this blog. The aim was to see how the process of creating and training a model is done. And how this model can be put to use. We will discuss some of the main aspects of the architecture in the future blogs and hopefully do a PyTorch series to learn how everything works in the background. This is it for now."
  },
  {
    "objectID": "posts/vision/04-neural-networks-in-pytorch.html#introduction",
    "href": "posts/vision/04-neural-networks-in-pytorch.html#introduction",
    "title": "Neural Networks in PyTorch | Log #004",
    "section": "",
    "text": "Until now, we have understood what an image is and the operations that are done to better extract information from them. Now it’s time to dive deep into Neural Networks. This blog will introduce a lot of new concepts and I hope to write separate blogs explaining some of those concepts in depth.\nPyTorch is one of the most popular deep learning frameworks and provides some of the core functionalities required for building a neural network. I find this highly intuitive and there’s always scope to dig deep if want to better understand something by writing from scratch.\n\n\nPyTorch has domain specific libraries like torchtext, torchvision, torchaudio which provide very useful building blocks along with some of the popular datasets.\nFor this example, we will do a simple image classification task with FashionMNIST dataset. The dataset consists of 28x28 grayscale images, each associated with a single label from 10 classes. There are 60k training examples and 10k testing examples.\n\nimport torch\nfrom torch import nn\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom torch.utils.data import DataLoader\n\ntraining_data = datasets.FashionMNIST(root=\"data\", download=True, train=True, transform=ToTensor())\ntest_data = datasets.FashionMNIST(root=\"data\", download=True, train=False, transform=ToTensor())\n\nThe above code downloads the data into the root folder and applys the transformations. This provides a Dataset object that stores the sample and their corresponding labels. We want to batch our data to feed them into the model iteratively, using the DataLoader class. This wraps an iterable over the dataset and supports multiprocess data loading and automatic batching.\n\nbatch_size = 64\n\ntrain_dataloader = DataLoader(dataset=training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(dataset=test_data, batch_size=batch_size)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"------------- Using {device} ------------\")\n\nWe have created a batch of 64 elements in the dataloader which will return 64 features and labels per batch.\n\n\n\nNow let’s create a simple neural network. Every module in PyTorch inherits from nn.Module. We will define our model in the __init__ function and the forward pass in forward funtion which get’s called automatically.\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = NeuralNetwork().to(device)\nprint(model)\n\nNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\n\nNow that we have a model, let’s define a loss function and an optimizer which will help us train the model.\nLoss function simply measures the difference between the predicted output value and the actual target value. This loss is what we need to minimize during training.\nOptimizer is defined as the process of reducing the model error step by step during training. And there are many ways to implement this. This is how our model is learning to perform better. In a training loop, we call the optimizer to replace the gradients of model paramenters using backpropagation. We will look into these algorithms in depth separately.\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = loss_fn(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    if batch % 100==0:\n        loss, current = loss.item(), (batch + 1) * len(x)\n        print(f\"Training: \\n loss: {loss:&gt;7f} [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss = loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \\n\")\n\nWe pass the train and test data through the model and calculate the losses and accuracy. Each full pass through the data is called an Epoch.\n\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\nNow that we have a model, we can save it and load for deployment. We can also do inference to see how the model performs for new data.\n\ntorch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch model state to model.pth\")\n\n\nmodel = NeuralNetwork().to(device)\nmodel.load_state_dict(torch.load(\"model.pth\"), weights_only=True)\n\n\nclasses = [\n    \"T-shirt/top\",\n    \"Trouser\",\n    \"Pullover\",\n    \"Dress\",\n    \"Coat\",\n    \"Sandal\",\n    \"Shirt\",\n    \"Sneaker\",\n    \"Bag\",\n    \"Ankle boot\",\n]\n\nmodel.eval()\nx, y = test_data[0][0], test_data[0][1]\nwith torch.no_grad():\n    x = x.to(device)\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n\nThere is a lot of concepts we introduced in this blog. The aim was to see how the process of creating and training a model is done. And how this model can be put to use. We will discuss some of the main aspects of the architecture in the future blogs and hopefully do a PyTorch series to learn how everything works in the background. This is it for now."
  },
  {
    "objectID": "posts/vision/02-understanding-images-as-data.html",
    "href": "posts/vision/02-understanding-images-as-data.html",
    "title": "Understanding Images as Data | Log #002",
    "section": "",
    "text": "An image is a grid of tiny squares called pixels. Each pixel is a single point of colour in the image. The resolution of an image is basically group of pixels arranged in a grid format. n x n is basically the number of pixels in an image represented as n rows and columns."
  },
  {
    "objectID": "posts/vision/02-understanding-images-as-data.html#introduction",
    "href": "posts/vision/02-understanding-images-as-data.html#introduction",
    "title": "Understanding Images as Data | Log #002",
    "section": "",
    "text": "An image is a grid of tiny squares called pixels. Each pixel is a single point of colour in the image. The resolution of an image is basically group of pixels arranged in a grid format. n x n is basically the number of pixels in an image represented as n rows and columns."
  },
  {
    "objectID": "posts/vision/02-understanding-images-as-data.html#representation-of-color-spaces",
    "href": "posts/vision/02-understanding-images-as-data.html#representation-of-color-spaces",
    "title": "Understanding Images as Data | Log #002",
    "section": "Representation of Color Spaces",
    "text": "Representation of Color Spaces\nImages are described in different color spaces. We will only look at some important ways to represent images that are useful for machine learning tasks.\n\nRGB (Red, Green, Blue)\nRBG is the most common way to store pixel values. Each pixel contains 3 numbers between the values of 0-255. For example, red would be (255, 0, 0).\nGrayscale\nGrayscale images are represented using a single number per pixel between 0-255. 0 represents black, 255 represents white and the values in between are different shades of grey.\nHSV (Hue, Saturation, Value)\nHSV separates the color and intensity information in a way that’s more intuitive. There are many formats that are used to represent HSV, the standard format is as follows:\n\nHue - ranges from 0o to 360o and represents the color type\nSaturation - ranges from 0% (no color, grayscale) - 100% (pure color) and represents the intensity of the color\nValue - ranges from 0% - 100% and represents the brightness of the color\n\n\nIn the interest of keeping these blogs short, we will stop here and discuss diffent ways of image manipulation in the next ones."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a Data Scientist with over 5 years of experience in software engineering and have worked in a variety of roles, including Data Engineering, Sofware Development and Machine Learning.\nI like to dive deep into topics that peak my interest and this blog will be a place to share my learnings. I was inspired from this blog by Dr. Rachel Thomas from FastAI to start documenting my learning. Here are some of my favorite parts of the blog:\n\nThe top advice I would give my younger self would be to start blogging sooner.\n\n\nHelps you learn. Organizing knowledge always helps me synthesize my own ideas. One of the tests of whether you understand something is whether you can explain it to someone else. A blog post is a great way to do that.\n\n\nYou are best positioned to help people one step behind you.\n\nI am hoping that this blog will keep me disciplined when the discomfort of learning new things becomes real."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blogs",
    "section": "",
    "text": "Backpropagation | Log #005\n\n\n\nVision\n\n\n\nHow does the NN learn ?\n\n\n\nHemanth KR\n\n\nJan 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeural Networks in PyTorch | Log #004\n\n\n\nVision\n\n\nPyTorch\n\n\n\nLet’s build a simple NN in PyTorch\n\n\n\nHemanth KR\n\n\nJan 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImage Augmentation | Log #003\n\n\n\nVision\n\n\n\nResize, Crop, Rotate, Flip…\n\n\n\nHemanth KR\n\n\nJan 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Images as Data | Log #002\n\n\n\nVision\n\n\n\nWhat is an image ?\n\n\n\nHemanth KR\n\n\nJan 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputer Vision | Log #001\n\n\n\nVision\n\n\n\nAn introduction to CV\n\n\n\nHemanth KR\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/vision/01-computer-vision.html",
    "href": "posts/vision/01-computer-vision.html",
    "title": "Computer Vision | Log #001",
    "section": "",
    "text": "Computer Vision refers to teaching machines to understand and extract information from images and video. There has been research dating back to 1960s to extract contextual information from a visual input and it is a good read for those who are interested. For now let’s stick to understanding the modern approach that started with the breakthrough in 2012. AlexNet introduced in 2012 used Convolutional Neural Networks to solve image recognition with a significantly higher accuracy."
  },
  {
    "objectID": "posts/vision/01-computer-vision.html#introduction",
    "href": "posts/vision/01-computer-vision.html#introduction",
    "title": "Computer Vision | Log #001",
    "section": "",
    "text": "Computer Vision refers to teaching machines to understand and extract information from images and video. There has been research dating back to 1960s to extract contextual information from a visual input and it is a good read for those who are interested. For now let’s stick to understanding the modern approach that started with the breakthrough in 2012. AlexNet introduced in 2012 used Convolutional Neural Networks to solve image recognition with a significantly higher accuracy."
  },
  {
    "objectID": "posts/vision/01-computer-vision.html#computer-vision-vs-image-processing",
    "href": "posts/vision/01-computer-vision.html#computer-vision-vs-image-processing",
    "title": "Computer Vision | Log #001",
    "section": "Computer Vision vs Image Processing",
    "text": "Computer Vision vs Image Processing\nBut before we get ahead of ourself, let’s understand what is the difference between traditional image processing and computer vision. Although they are related fields they differ in their approach and objectives.\n\n\n\n\n\n\nImage Processing\n\nPixel level operations to manipulate and enhance images\nFiltering, color adjustments, transformations\nWorks at lower level of abstraction with pixel-level features\nDoes not involve learning from data and less demanding\n\n\n\nComputer Vision\n\nAnalysing image content and extract meaningful insights\nObject Recognition, Segmentation, Tracking\nHigher level of abstraction, analyzing contents of the image\nLearning features and patterns from datasets and requires large resources"
  },
  {
    "objectID": "posts/vision/01-computer-vision.html#applications",
    "href": "posts/vision/01-computer-vision.html#applications",
    "title": "Computer Vision | Log #001",
    "section": "Applications",
    "text": "Applications\nSome of the main applications of computer vision are as follows:\n\nImage Classification\nObject Detection\nSemantic Segmentation\nInstance Segmentation\nPose Estimation\nFace and Person Recognition\nImage Restoration"
  },
  {
    "objectID": "posts/vision/01-computer-vision.html#challenges",
    "href": "posts/vision/01-computer-vision.html#challenges",
    "title": "Computer Vision | Log #001",
    "section": "Challenges",
    "text": "Challenges\nThere are many challenges in computer vision that we are yet to overcome such as accuiring accurate large datasets that are labelled, removing bias in datasets, choosing the right architecture for a model, real-time processing and optimizing the computational requirements, etc.\nWe will work on getting a deeper understanding into this field in the future blogs."
  },
  {
    "objectID": "posts/vision/03-image-augmentations.html",
    "href": "posts/vision/03-image-augmentations.html",
    "title": "Image Augmentation | Log #003",
    "section": "",
    "text": "Image augmentation techniques are very useful in various computer vision tasks. They are used to achieve several objectives like improving model performance, expanding limited datasets, etc. Let’s look at how this is achieved before looking at types of augmentations."
  },
  {
    "objectID": "posts/vision/03-image-augmentations.html#reasons-to-augment",
    "href": "posts/vision/03-image-augmentations.html#reasons-to-augment",
    "title": "Image Augmentation | Log #003",
    "section": "Reasons to Augment",
    "text": "Reasons to Augment\n\nPrevent overfitting -\nBy creating variations of original images, the model gets exposed to wider reange of possible inputs, making it more generalizable.\nExpanding Datasets -\nWhen working with small datasets, augmentation can increase the size of the training data. This is useful in deep learning as models generally need a large amount of data to perform better.\nReal-world challenges -\nImage recognition task often face challenges like occulusion, light intensity and different angles. This can be introduced to the model at training stages with augmentation so the model can learn to perform under difficulties.\n\nWhile this is benificial, the effectiveness of image augmentation should be carefully chosen depending on the specific task. It could potentially reduce the model performance in some cases when the image augmentation technique is not selected appropriately."
  },
  {
    "objectID": "posts/vision/03-image-augmentations.html#types-of-augmentation",
    "href": "posts/vision/03-image-augmentations.html#types-of-augmentation",
    "title": "Image Augmentation | Log #003",
    "section": "Types of Augmentation",
    "text": "Types of Augmentation\nCommon image augmentation techniques are as follows:\n\nHorizontal and vertical flipping, rotating by various angles, increasing or decreasing image size, random selection and resizing portions of the image, randomly altering color channels, converting to grayscale, applying Gaussian noise, blurring techniques and so on.\n\nThere are many ways to implement these techniques, I am going to be using PyTorch to show a few methods.\nfrom torchvision import transforms\n\n# Resize an image\nresize = transforms.Resize((32, 32))\nresized_img = resize(img)\n\n# Rotate an image\nrotate = transforms.RandomRotation(degrees=90)\nrotated_img = rotate(img)\nWe can also chain multiple transforms in PyTorch and apply it to our DataLoader class.\nfrom torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor()\n])\nIn the above example we have chained the transforms using Compose and converted the image to a PyTorch tensor to prepare the image data in a PyTorch optimized format to ensure compatability.\nIn the next blog we’ll look at Neural Networks and how they learn using this image data."
  },
  {
    "objectID": "posts/vision/05-back-propagation.html",
    "href": "posts/vision/05-back-propagation.html",
    "title": "Backpropagation | Log #005",
    "section": "",
    "text": "Previously, we saw how to build a neural network that does image classification. Before we explore different neural network architectures and types of problems in computer vision, let’s spend some time understanding how the neural network actually learns.\nFrom my limited understanding, arguably the most important algorithm that we have come up with throughout history could be Backpropagation. Without the ability to learn non-linear properties from a dataset efficiently, neural networks might not have been so useful to us. So understanding it very crucial."
  },
  {
    "objectID": "posts/vision/05-back-propagation.html#introduction",
    "href": "posts/vision/05-back-propagation.html#introduction",
    "title": "Backpropagation | Log #005",
    "section": "",
    "text": "Previously, we saw how to build a neural network that does image classification. Before we explore different neural network architectures and types of problems in computer vision, let’s spend some time understanding how the neural network actually learns.\nFrom my limited understanding, arguably the most important algorithm that we have come up with throughout history could be Backpropagation. Without the ability to learn non-linear properties from a dataset efficiently, neural networks might not have been so useful to us. So understanding it very crucial."
  },
  {
    "objectID": "posts/vision/05-back-propagation.html#implementation",
    "href": "posts/vision/05-back-propagation.html#implementation",
    "title": "Backpropagation | Log #005",
    "section": "Implementation",
    "text": "Implementation\nThe core of backpropagation involves calculating the partial derivative of the cost function C with respect to each weight w in the network:\n\\[ ∂C/∂w \\]​\nThis gradient tells us how much a small change in each weight affects the overall error.\nDuring the neural network’s training process, the algorithm has two phases:\n\nForward Pass: Input data is passed through the network. As the data passes through the layers, each neuron will apply their weights, biases and activation functions. The ouput is produced depending on the final layer activation functions of the neurons.\nBackward Pass: The error between the desired output and network’s output is calculated using the loss function. This error is propagated backwards through the network layer by layer. Using the chain rule, the gradients of the error for each weight is calculated. And finally weights are updated based on these gradients and a learning rate.\n\nThis whole process is repeated multiple times which is called epochs."
  },
  {
    "objectID": "posts/vision/05-back-propagation.html#key-takeaways",
    "href": "posts/vision/05-back-propagation.html#key-takeaways",
    "title": "Backpropagation | Log #005",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nKey thing to note here is that the weights are updated using an optimization algorithm called gradient descent. There are many ways to implement this depending on the type of problem and dataset size. And there are also many types of loss functions and activation functions. These are crutial to understanding the architecture of a Neural Network. We will look at all these functions in the upcoming blogs."
  }
]